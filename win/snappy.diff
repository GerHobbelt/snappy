diff --git a/snappy-c.h b/snappy-c.h
index 32aa0c6..ac9cf93 100644
--- a/snappy-c.h
+++ b/snappy-c.h
@@ -33,6 +33,14 @@
 #ifndef THIRD_PARTY_SNAPPY_OPENSOURCE_SNAPPY_C_H_
 #define THIRD_PARTY_SNAPPY_OPENSOURCE_SNAPPY_C_H_
 
+#ifndef __SNAPPY_API
+#ifdef _MSC_VER
+#include "snappy-dll.h"
+#else
+#define __SNAPPY_API
+#endif
+#endif
+
 #ifdef __cplusplus
 extern "C" {
 #endif
@@ -68,6 +76,7 @@ typedef enum {
  *   }
  *   free(output);
  */
+__SNAPPY_API
 snappy_status snappy_compress(const char* input,
                               size_t input_length,
                               char* compressed,
@@ -100,6 +109,7 @@ snappy_status snappy_compress(const char* input,
  *   }
  *   free(output);
  */
+__SNAPPY_API
 snappy_status snappy_uncompress(const char* compressed,
                                 size_t compressed_length,
                                 char* uncompressed,
@@ -109,6 +119,7 @@ snappy_status snappy_uncompress(const char* compressed,
  * Returns the maximal size of the compressed representation of
  * input data that is "source_length" bytes in length.
  */
+__SNAPPY_API
 size_t snappy_max_compressed_length(size_t source_length);
 
 /*
@@ -117,6 +128,7 @@ size_t snappy_max_compressed_length(size_t source_length);
  * *result normally. Returns SNAPPY_INVALID_INPUT on parsing error.
  * This operation takes O(1) time.
  */
+__SNAPPY_API
 snappy_status snappy_uncompressed_length(const char* compressed,
                                          size_t compressed_length,
                                          size_t* result);
@@ -128,6 +140,7 @@ snappy_status snappy_uncompressed_length(const char* compressed,
  * Takes time proportional to compressed_length, but is usually at least a
  * factor of four faster than actual decompression.
  */
+__SNAPPY_API
 snappy_status snappy_validate_compressed_buffer(const char* compressed,
                                                 size_t compressed_length);
 
diff --git a/snappy-internal.h b/snappy-internal.h
index c4d1f6d..09e25b9 100644
--- a/snappy-internal.h
+++ b/snappy-internal.h
@@ -33,10 +33,18 @@
 
 #include "snappy-stubs-internal.h"
 
+#ifndef __SNAPPY_API
+#ifdef _MSC_VER
+#include "snappy-dll.h"
+#else
+#define __SNAPPY_API
+#endif
+#endif
+
 namespace snappy {
 namespace internal {
 
-class WorkingMemory {
+class __SNAPPY_API WorkingMemory {
  public:
   WorkingMemory() : large_table_(NULL) { }
   ~WorkingMemory() { delete[] large_table_; }
@@ -44,7 +52,7 @@ class WorkingMemory {
   // Allocates and clears a hash table using memory in "*this",
   // stores the number of buckets in "*table_size" and returns a pointer to
   // the base of the hash table.
-  uint16* GetHashTable(size_t input_size, int* table_size);
+  uint16* GetHashTable(size_t input_size, size_t* table_size);
 
  private:
   uint16 small_table_[1<<10];    // 2KB
@@ -64,11 +72,12 @@ class WorkingMemory {
 //
 // Returns an "end" pointer into "op" buffer.
 // "end - op" is the compressed size of "input".
+__SNAPPY_API
 char* CompressFragment(const char* input,
                        size_t input_length,
                        char* op,
                        uint16* table,
-                       const int table_size);
+                       const size_t table_size);
 
 // Return the largest n such that
 //
diff --git a/snappy-sinksource.h b/snappy-sinksource.h
index 8afcdaa..28ebf78 100644
--- a/snappy-sinksource.h
+++ b/snappy-sinksource.h
@@ -31,10 +31,18 @@
 
 #include <stddef.h>
 
+#ifndef __SNAPPY_API
+#ifdef _MSC_VER
+#include "snappy-dll.h"
+#else
+#define __SNAPPY_API
+#endif
+#endif
+
 namespace snappy {
 
 // A Sink is an interface that consumes a sequence of bytes.
-class Sink {
+class __SNAPPY_API Sink {
  public:
   Sink() { }
   virtual ~Sink();
@@ -108,7 +116,7 @@ class Sink {
 };
 
 // A Source is an interface that yields a sequence of bytes
-class Source {
+class __SNAPPY_API Source {
  public:
   Source() { }
   virtual ~Source();
@@ -143,7 +151,7 @@ class Source {
 };
 
 // A Source implementation that yields the contents of a flat array
-class ByteArraySource : public Source {
+class __SNAPPY_API ByteArraySource : public Source {
  public:
   ByteArraySource(const char* p, size_t n) : ptr_(p), left_(n) { }
   virtual ~ByteArraySource();
@@ -156,7 +164,7 @@ class ByteArraySource : public Source {
 };
 
 // A Sink implementation that writes to a flat array without any bound checks.
-class UncheckedByteArraySink : public Sink {
+class __SNAPPY_API UncheckedByteArraySink : public Sink {
  public:
   explicit UncheckedByteArraySink(char* dest) : dest_(dest) { }
   virtual ~UncheckedByteArraySink();
diff --git a/snappy-stubs-internal.h b/snappy-stubs-internal.h
index 1954c63..28aa2f2 100644
--- a/snappy-stubs-internal.h
+++ b/snappy-stubs-internal.h
@@ -47,6 +47,14 @@
 
 #include "snappy-stubs-public.h"
 
+#ifndef __SNAPPY_API
+#ifdef _MSC_VER
+#include "snappy-dll.h"
+#else
+#define __SNAPPY_API
+#endif
+#endif
+
 #if defined(__x86_64__)
 
 // Enable 64-bit optimized versions of some routines.
@@ -427,7 +435,7 @@ inline int Bits::FindLSBSetNonZero64(uint64 n) {
 #endif  // End portable versions.
 
 // Variable-length integer encoding.
-class Varint {
+class __SNAPPY_API Varint {
  public:
   // Maximum lengths of varint encoding of uint32.
   static const int kMax32 = 5;
diff --git a/snappy-test.cc b/snappy-test.cc
index 7f1d0a8..4d6dea3 100644
--- a/snappy-test.cc
+++ b/snappy-test.cc
@@ -47,10 +47,20 @@ namespace snappy {
 
 string ReadTestDataFile(const string& base, size_t size_limit) {
   string contents;
+#ifdef _MSC_VER
+  char* srcdir = NULL;
+  size_t srcdirlen = 0;
+  if (_dupenv_s(&srcdir, &srcdirlen, "srcdir") != 0) // This is set by Automake.
+     srcdir = NULL;
+#else
   const char* srcdir = getenv("srcdir");  // This is set by Automake.
+#endif
   string prefix;
   if (srcdir) {
     prefix = string(srcdir) + "/";
+#ifdef _MSC_VER
+    free(srcdir);
+#endif
   }
   file::GetContents(prefix + "testdata/" + base, &contents, file::Defaults()
       ).CheckSuccess();
@@ -68,9 +78,14 @@ string StringPrintf(const char* format, ...) {
   char buf[4096];
   va_list ap;
   va_start(ap, format);
+  int const n =
+#ifdef _MSC_VER
+  _vsnprintf_s(buf, _TRUNCATE, format, ap);
+#else
   vsnprintf(buf, sizeof(buf), format, ap);
+#endif
   va_end(ap);
-  return buf;
+  return string(buf, (0 <= n && n < sizeof(buf)) ? n : (sizeof(buf)-1));
 }
 
 bool benchmark_running = false;
@@ -122,7 +137,7 @@ void StopBenchmarkTiming() {
   double elapsed_real = static_cast<double>(
       benchmark_stop_real.QuadPart - benchmark_start_real.QuadPart) /
       benchmark_frequency.QuadPart;
-  benchmark_real_time_us += elapsed_real * 1e6 + 0.5;
+  benchmark_real_time_us += static_cast<int64>(elapsed_real * 1e6 + 0.5);
 
   FILETIME benchmark_stop_cpu, dummy;
   CHECK(GetProcessTimes(
@@ -186,7 +201,7 @@ void Benchmark::Run() {
   for (int test_case_num = start_; test_case_num <= stop_; ++test_case_num) {
     // Run a few iterations first to find out approximately how fast
     // the benchmark is.
-    const int kCalibrateIterations = 100;
+    const int64 kCalibrateIterations = 100;
     ResetBenchmarkTiming();
     StartBenchmarkTiming();
     (*function_)(kCalibrateIterations, test_case_num);
@@ -197,7 +212,7 @@ void Benchmark::Run() {
     // Run five times and pick the median.
     const int kNumRuns = 5;
     const int kMedianPos = kNumRuns / 2;
-    int num_iterations = 0;
+    int64 num_iterations = 0;
     if (benchmark_real_time_us > 0) {
       num_iterations = 200000 * kCalibrateIterations / benchmark_real_time_us;
     }
@@ -207,7 +222,7 @@ void Benchmark::Run() {
     for (int run = 0; run < kNumRuns; ++run) {
       ResetBenchmarkTiming();
       StartBenchmarkTiming();
-      (*function_)(num_iterations, test_case_num);
+      (*function_)(static_cast<int>(num_iterations), test_case_num);
       StopBenchmarkTiming();
 
       benchmark_runs[run].real_time_us = benchmark_real_time_us;
@@ -229,7 +244,7 @@ void Benchmark::Run() {
       int64 bytes_per_second =
           benchmark_bytes_processed * 1000000 / cpu_time_us;
       if (bytes_per_second < 1024) {
-        human_readable_speed = StringPrintf("%dB/s", bytes_per_second);
+        human_readable_speed = StringPrintf("%dB/s", static_cast<int>(bytes_per_second));
       } else if (bytes_per_second < 1024 * 1024) {
         human_readable_speed = StringPrintf(
             "%.1fkB/s", bytes_per_second / 1024.0f);
@@ -243,10 +258,10 @@ void Benchmark::Run() {
     }
 
     fprintf(stderr,
-#ifdef WIN32
-            "%-18s %10I64d %10I64d %10d %s  %s\n",
+#if defined(_MSC_VER) && _MSC_VER < 1600
+            "%-18s %10I64d %10I64d %10I64d %12s  %s\n",
 #else
-            "%-18s %10lld %10lld %10d %s  %s\n",
+            "%-18s %10lld %10lld %10lld %12s  %s\n",
 #endif
             heading.c_str(),
             static_cast<long long>(real_time_us * 1000 / num_iterations),
diff --git a/snappy-test.h b/snappy-test.h
index 5fb09c7..eb797a8 100644
--- a/snappy-test.h
+++ b/snappy-test.h
@@ -139,7 +139,12 @@ namespace file {
   };
 
   DummyStatus GetContents(const string& filename, string* data, int unused) {
+#ifdef _MSC_VER
+    FILE* fp = NULL;
+    if (fopen_s(&fp, filename.c_str(), "rb") != 0) fp = NULL;
+#else
     FILE* fp = fopen(filename.c_str(), "rb");
+#endif
     if (fp == NULL) {
       perror(filename.c_str());
       exit(1);
@@ -164,13 +169,18 @@ namespace file {
   DummyStatus SetContents(const string& filename,
                           const string& str,
                           int unused) {
+#ifdef _MSC_VER
+    FILE* fp = NULL;
+    if (fopen_s(&fp, filename.c_str(), "wb") != 0) fp = NULL;
+#else
     FILE* fp = fopen(filename.c_str(), "wb");
+#endif
     if (fp == NULL) {
       perror(filename.c_str());
       exit(1);
     }
 
-    int ret = fwrite(str.data(), str.size(), 1, fp);
+    size_t ret = fwrite(str.data(), str.size(), 1, fp);
     if (ret != 1) {
       perror("fwrite");
       exit(1);
@@ -245,7 +255,7 @@ inline int32 ACMRandom::Next() {
   uint64 product = seed_ * A;
 
   // Compute (product % M) using the fact that ((x << 31) % M) == x.
-  seed_ = (product >> 31) + (product & M);
+  seed_ = static_cast<uint32>((product >> 31) + (product & M));
   // The first reduction may overflow by 1 bit, so we may need to repeat.
   // mod == M is not possible; using > allows the faster sign-bit-based test.
   if (seed_ > M) {
@@ -282,7 +292,7 @@ class CycleTimer {
 
     double elapsed = static_cast<double>(stop.QuadPart - start_.QuadPart) /
         frequency.QuadPart;
-    real_time_us_ += elapsed * 1e6 + 0.5;
+    real_time_us_ += static_cast<int64>(elapsed * 1e6 + 0.5);
 #else
     struct timeval stop;
     gettimeofday(&stop, NULL);
@@ -476,7 +486,7 @@ static void RunSpecifiedBenchmarks() {
 #ifndef NDEBUG
   fprintf(stderr, "WARNING: Compiled with assertions enabled, will be slow.\n");
 #endif
-#ifndef __OPTIMIZE__
+#if !(defined(__GNUC__) && defined(__OPTIMIZE__)) && !(defined(_MSC_VER) && defined(NDEBUG))
   fprintf(stderr, "WARNING: Compiled without optimization, will be slow.\n");
 #endif
   fprintf(stderr, "Benchmark            Time(ns)    CPU(ns) Iterations\n");
@@ -532,12 +542,9 @@ class LogMessage {
     cerr << endl;
   }
 
-  LogMessage& operator<<(const std::string& msg) {
-    cerr << msg;
-    return *this;
-  }
-  LogMessage& operator<<(int x) {
-    cerr << x;
+  template<typename _T>
+  LogMessage& operator<<(const _T& value) {
+    cerr << value;
     return *this;
   }
 };
diff --git a/snappy.cc b/snappy.cc
index 8a3668c..15b5b9c 100644
--- a/snappy.cc
+++ b/snappy.cc
@@ -203,11 +203,11 @@ static inline char* EmitCopyLessThan64(char* op, size_t offset, int len) {
   if ((len < 12) && (offset < 2048)) {
     size_t len_minus_4 = len - 4;
     assert(len_minus_4 < 8);            // Must fit in 3 bits
-    *op++ = COPY_1_BYTE_OFFSET + ((len_minus_4) << 2) + ((offset >> 8) << 5);
-    *op++ = offset & 0xff;
+    *op++ = static_cast<char>(COPY_1_BYTE_OFFSET + ((len_minus_4) << 2) + ((offset >> 8) << 5));
+    *op++ = static_cast<char>(offset & 0xff);
   } else {
     *op++ = COPY_2_BYTE_OFFSET + ((len-1) << 2);
-    LittleEndian::Store16(op, offset);
+    LittleEndian::Store16(op, static_cast<uint16>(offset));
     op += 2;
   }
   return op;
@@ -244,7 +244,7 @@ bool GetUncompressedLength(const char* start, size_t n, size_t* result) {
 }
 
 namespace internal {
-uint16* WorkingMemory::GetHashTable(size_t input_size, int* table_size) {
+uint16* WorkingMemory::GetHashTable(size_t input_size, size_t* table_size) {
   // Use smaller hash table when input.size() is smaller, since we
   // fill the table, incurring O(hash table size) overhead for
   // compression, and if the input is short, we won't need that
@@ -330,12 +330,12 @@ char* CompressFragment(const char* input,
                        size_t input_size,
                        char* op,
                        uint16* table,
-                       const int table_size) {
+                       const size_t table_size) {
   // "ip" is the input pointer, and "op" is the output pointer.
   const char* ip = input;
   assert(input_size <= kBlockSize);
   assert((table_size & (table_size - 1)) == 0); // table must be power of two
-  const int shift = 32 - Bits::Log2Floor(table_size);
+  const int shift = 32 - Bits::Log2Floor(static_cast<uint32>(table_size));
   assert(static_cast<int>(kuint32max >> shift) == table_size - 1);
   const char* ip_end = input + input_size;
   const char* base_ip = ip;
@@ -393,7 +393,7 @@ char* CompressFragment(const char* input,
         assert(candidate >= base_ip);
         assert(candidate < ip);
 
-        table[hash] = ip - base_ip;
+        table[hash] = static_cast<uint16>(ip - base_ip);
       } while (PREDICT_TRUE(UNALIGNED_LOAD32(ip) !=
                             UNALIGNED_LOAD32(candidate)));
 
@@ -401,7 +401,7 @@ char* CompressFragment(const char* input,
       // than 4 bytes match.  But, prior to the match, input
       // bytes [next_emit, ip) are unmatched.  Emit them as "literal bytes."
       assert(next_emit + 16 <= ip_end);
-      op = EmitLiteral(op, next_emit, ip - next_emit, true);
+      op = EmitLiteral(op, next_emit, static_cast<int>(ip - next_emit), true);
 
       // Step 3: Call EmitCopy, and then see if another EmitCopy could
       // be our next move.  Repeat until we find no match for the
@@ -432,11 +432,11 @@ char* CompressFragment(const char* input,
         }
         input_bytes = GetEightBytesAt(insert_tail);
         uint32 prev_hash = HashBytes(GetUint32AtOffset(input_bytes, 0), shift);
-        table[prev_hash] = ip - base_ip - 1;
+        table[prev_hash] = static_cast<uint16>(ip - base_ip - 1);
         uint32 cur_hash = HashBytes(GetUint32AtOffset(input_bytes, 1), shift);
         candidate = base_ip + table[cur_hash];
         candidate_bytes = UNALIGNED_LOAD32(candidate);
-        table[cur_hash] = ip - base_ip;
+        table[cur_hash] = static_cast<uint16>(ip - base_ip);
       } while (GetUint32AtOffset(input_bytes, 1) == candidate_bytes);
 
       next_hash = HashBytes(GetUint32AtOffset(input_bytes, 2), shift);
@@ -447,7 +447,7 @@ char* CompressFragment(const char* input,
  emit_remainder:
   // Emit the remaining bytes as a literal
   if (next_emit < ip_end) {
-    op = EmitLiteral(op, next_emit, ip_end - next_emit, false);
+    op = EmitLiteral(op, next_emit, static_cast<int>(ip_end - next_emit), false);
   }
 
   return op;
@@ -604,7 +604,7 @@ class SnappyDecompressor {
           size_t n;
           ip = reader_->Peek(&n);
           avail = n;
-          peeked_ = avail;
+          peeked_ = static_cast<uint32>(avail);
           if (avail == 0) return;  // Premature end of input
           ip_limit_ = ip + avail;
         }
@@ -641,7 +641,7 @@ bool SnappyDecompressor::RefillTag() {
     reader_->Skip(peeked_);   // All peeked bytes are used up
     size_t n;
     ip = reader_->Peek(&n);
-    peeked_ = n;
+    peeked_ = static_cast<uint32>(n);
     if (n == 0) {
       eof_ = true;
       return false;
@@ -653,11 +653,11 @@ bool SnappyDecompressor::RefillTag() {
   assert(ip < ip_limit_);
   const unsigned char c = *(reinterpret_cast<const unsigned char*>(ip));
   const uint32 entry = char_table[c];
-  const uint32 needed = (entry >> 11) + 1;  // +1 byte for 'c'
+  const size_t needed = (entry >> 11) + 1;  // +1 byte for 'c'
   assert(needed <= sizeof(scratch_));
 
   // Read more bytes from reader if needed
-  uint32 nbuf = ip_limit_ - ip;
+  size_t nbuf = ip_limit_ - ip;
   if (nbuf < needed) {
     // Stitch together bytes from ip and reader to form the word
     // contents.  We store the needed bytes in "scratch_".  They
@@ -670,7 +670,7 @@ bool SnappyDecompressor::RefillTag() {
       size_t length;
       const char* src = reader_->Peek(&length);
       if (length == 0) return false;
-      uint32 to_add = min<uint32>(needed - nbuf, length);
+      size_t to_add = min(needed - nbuf, length);
       memcpy(scratch_ + nbuf, src, to_add);
       nbuf += to_add;
       reader_->Skip(to_add);
@@ -723,7 +723,7 @@ size_t Compress(Source* reader, Sink* writer) {
   size_t written = 0;
   size_t N = reader->Available();
   char ulength[Varint::kMax32];
-  char* p = Varint::Encode32(ulength, N);
+  char* p = Varint::Encode32(ulength, static_cast<uint32>(N));
   writer->Append(ulength, p-ulength);
   written += (p - ulength);
 
@@ -769,11 +769,11 @@ size_t Compress(Source* reader, Sink* writer) {
     assert(fragment_size == num_to_read);
 
     // Get encoding table for compression
-    int table_size;
+    size_t table_size;
     uint16* table = wmem.GetHashTable(num_to_read, &table_size);
 
     // Compress input_fragment and append to dest
-    const int max_output = MaxCompressedLength(num_to_read);
+    const size_t max_output = MaxCompressedLength(num_to_read);
 
     // Need a scratch buffer for the output, in case the byte sink doesn't
     // have room for us directly.
@@ -1229,7 +1229,7 @@ class SnappyScatteredWriter {
 
   inline bool TryFastAppend(const char* ip, size_t available, size_t length) {
     char* op = op_ptr_;
-    const int space_left = op_limit_ - op;
+    const size_t space_left = op_limit_ - op;
     if (length <= 16 && available >= 16 + kMaximumTagLength &&
         space_left >= 16) {
       // Fast path, used for the majority (about 95%) of invocations.
@@ -1245,7 +1245,7 @@ class SnappyScatteredWriter {
   inline bool AppendFromSelf(size_t offset, size_t len) {
     // See SnappyArrayWriter::AppendFromSelf for an explanation of
     // the "offset - 1u" trick.
-    if (offset - 1u < op_ptr_ - op_base_) {
+    if (offset < size_t(op_ptr_ - op_base_) + 1) {
       const size_t space_left = op_limit_ - op_ptr_;
       if (space_left >= len + kMaxIncrementCopyOverflow) {
         // Fast path: src and dst in current block.
@@ -1322,7 +1322,7 @@ class SnappySinkAllocator {
   explicit SnappySinkAllocator(Sink* dest): dest_(dest) {}
   ~SnappySinkAllocator() {}
 
-  char* Allocate(int size) {
+  char* Allocate(size_t size) {
     Datablock block(new char[size], size);
     blocks_.push_back(block);
     return block.data;
@@ -1336,7 +1336,7 @@ class SnappySinkAllocator {
   void Flush(size_t size) {
     size_t size_written = 0;
     size_t block_size;
-    for (int i = 0; i < blocks_.size(); ++i) {
+    for (size_t i = 0; i < blocks_.size(); ++i) {
       block_size = min<size_t>(blocks_[i].size, size - size_written);
       dest_->AppendAndTakeOwnership(blocks_[i].data, block_size,
                                     &SnappySinkAllocator::Deleter, NULL);
diff --git a/snappy.h b/snappy.h
index 4568db8..1490ef2 100644
--- a/snappy.h
+++ b/snappy.h
@@ -44,6 +44,14 @@
 
 #include "snappy-stubs-public.h"
 
+#ifndef __SNAPPY_API
+#ifdef _MSC_VER
+#include "snappy-dll.h"
+#else
+#define __SNAPPY_API
+#endif
+#endif
+
 namespace snappy {
   class Source;
   class Sink;
@@ -54,6 +62,7 @@ namespace snappy {
 
   // Compress the bytes read from "*source" and append to "*sink". Return the
   // number of bytes written.
+  __SNAPPY_API
   size_t Compress(Source* source, Sink* sink);
 
   // Find the uncompressed length of the given stream, as given by the header.
@@ -63,6 +72,7 @@ namespace snappy {
   // Also note that this leaves "*source" in a state that is unsuitable for
   // further operations, such as RawUncompress(). You will need to rewind
   // or recreate the source yourself before attempting any further calls.
+  __SNAPPY_API
   bool GetUncompressedLength(Source* source, uint32* result);
 
   // ------------------------------------------------------------------------
@@ -73,6 +83,7 @@ namespace snappy {
   // Original contents of *output are lost.
   //
   // REQUIRES: "input[]" is not an alias of "*output".
+  __SNAPPY_API
   size_t Compress(const char* input, size_t input_length, string* output);
 
   // Decompresses "compressed[0,compressed_length-1]" to "*uncompressed".
@@ -81,12 +92,14 @@ namespace snappy {
   // REQUIRES: "compressed[]" is not an alias of "*uncompressed".
   //
   // returns false if the message is corrupted and could not be decompressed
+  __SNAPPY_API
   bool Uncompress(const char* compressed, size_t compressed_length,
                   string* uncompressed);
 
   // Decompresses "compressed" to "*uncompressed".
   //
   // returns false if the message is corrupted and could not be decompressed
+  __SNAPPY_API
   bool Uncompress(Source* compressed, Sink* uncompressed);
 
   // This routine uncompresses as much of the "compressed" as possible
@@ -95,6 +108,7 @@ namespace snappy {
   // should ignore those). The emitted data typically has length
   // GetUncompressedLength(), but may be shorter if an error is
   // encountered.
+  __SNAPPY_API
   size_t UncompressAsMuchAsPossible(Source* compressed, Sink* uncompressed);
 
   // ------------------------------------------------------------------------
@@ -116,6 +130,7 @@ namespace snappy {
   //    RawCompress(input, input_length, output, &output_length);
   //    ... Process(output, output_length) ...
   //    delete [] output;
+  __SNAPPY_API
   void RawCompress(const char* input,
                    size_t input_length,
                    char* compressed,
@@ -126,6 +141,7 @@ namespace snappy {
   // stores the uncompressed data to
   //    uncompressed[0..GetUncompressedLength(compressed)-1]
   // returns false if the message is corrupted and could not be decrypted
+  __SNAPPY_API
   bool RawUncompress(const char* compressed, size_t compressed_length,
                      char* uncompressed);
 
@@ -134,6 +150,7 @@ namespace snappy {
   // data to
   //    uncompressed[0..GetUncompressedLength(compressed,compressed_length)-1]
   // returns false if the message is corrupted and could not be decrypted
+  __SNAPPY_API
   bool RawUncompress(Source* compressed, char* uncompressed);
 
   // Given data in "compressed[0..compressed_length-1]" generated by
@@ -144,6 +161,7 @@ namespace snappy {
   // in "iov" must not overlap with each other.
   //
   // returns false if the message is corrupted and could not be decrypted
+  __SNAPPY_API
   bool RawUncompressToIOVec(const char* compressed, size_t compressed_length,
                             const struct iovec* iov, size_t iov_cnt);
 
@@ -155,17 +173,20 @@ namespace snappy {
   // in "iov" must not overlap with each other.
   //
   // returns false if the message is corrupted and could not be decrypted
+  __SNAPPY_API
   bool RawUncompressToIOVec(Source* compressed, const struct iovec* iov,
                             size_t iov_cnt);
 
   // Returns the maximal size of the compressed representation of
   // input data that is "source_bytes" bytes in length;
+  __SNAPPY_API
   size_t MaxCompressedLength(size_t source_bytes);
 
   // REQUIRES: "compressed[]" was produced by RawCompress() or Compress()
   // Returns true and stores the length of the uncompressed data in
   // *result normally.  Returns false on parsing error.
   // This operation takes O(1) time.
+  __SNAPPY_API
   bool GetUncompressedLength(const char* compressed, size_t compressed_length,
                              size_t* result);
 
@@ -173,6 +194,7 @@ namespace snappy {
   // successfully.  Does not return the uncompressed data.  Takes
   // time proportional to compressed_length, but is usually at least
   // a factor of four faster than actual decompression.
+  __SNAPPY_API
   bool IsValidCompressedBuffer(const char* compressed,
                                size_t compressed_length);
 
@@ -182,6 +204,7 @@ namespace snappy {
   // a factor of four faster than actual decompression.
   // On success, consumes all of *compressed.  On failure, consumes an
   // unspecified prefix of *compressed.
+  __SNAPPY_API
   bool IsValidCompressed(Source* compressed);
 
   // The size of a compression block. Note that many parts of the compression
diff --git a/snappy_unittest.cc b/snappy_unittest.cc
index 65ac16a..288e7b5 100644
--- a/snappy_unittest.cc
+++ b/snappy_unittest.cc
@@ -155,7 +155,7 @@ static size_t MinimumRequiredOutputSpace(size_t input_size,
 
 #ifdef FASTLZ_VERSION
     case FASTLZ:
-      return max(static_cast<int>(ceil(input_size * 1.05)), 66);
+      return max<size_t>(ceil(input_size * 1.05), 66);
 #endif  // FASTLZ_VERSION
 
     case SNAPPY:
@@ -289,7 +289,7 @@ static bool Compress(const char* input, size_t input_size, CompressorType comp,
 }
 
 static bool Uncompress(const string& compressed, CompressorType comp,
-                       int size, string* output) {
+                       size_t size, string* output) {
   switch (comp) {
 #ifdef ZLIB_VERSION
     case ZLIB: {
@@ -388,18 +388,18 @@ static void Measure(const char* data,
   static const int kRuns = 5;
   double ctime[kRuns];
   double utime[kRuns];
-  int compressed_size = 0;
+  size_t compressed_size = 0;
 
   {
     // Chop the input into blocks
-    int num_blocks = (length + block_size - 1) / block_size;
+    size_t num_blocks = (length + block_size - 1) / block_size;
     vector<const char*> input(num_blocks);
     vector<size_t> input_length(num_blocks);
     vector<string> compressed(num_blocks);
     vector<string> output(num_blocks);
-    for (int b = 0; b < num_blocks; b++) {
-      int input_start = b * block_size;
-      int input_limit = min<int>((b+1)*block_size, length);
+    for (size_t b = 0; b < num_blocks; b++) {
+      size_t input_start = b * block_size;
+      size_t input_limit = min((b+1)*block_size, length);
       input[b] = data+input_start;
       input_length[b] = input_limit-input_start;
 
@@ -417,30 +417,30 @@ static void Measure(const char* data,
     for (int run = 0; run < kRuns; run++) {
       CycleTimer ctimer, utimer;
 
-      for (int b = 0; b < num_blocks; b++) {
+      for (size_t b = 0; b < num_blocks; b++) {
         // Pre-grow the output buffer so we don't measure string append time.
         compressed[b].resize(MinimumRequiredOutputSpace(block_size, comp));
       }
 
       ctimer.Start();
-      for (int b = 0; b < num_blocks; b++)
+      for (size_t b = 0; b < num_blocks; b++)
         for (int i = 0; i < repeats; i++)
           Compress(input[b], input_length[b], comp, &compressed[b], true);
       ctimer.Stop();
 
       // Compress once more, with resizing, so we don't leave junk
       // at the end that will confuse the decompressor.
-      for (int b = 0; b < num_blocks; b++) {
+      for (size_t b = 0; b < num_blocks; b++) {
         Compress(input[b], input_length[b], comp, &compressed[b], false);
       }
 
-      for (int b = 0; b < num_blocks; b++) {
+      for (size_t b = 0; b < num_blocks; b++) {
         output[b].resize(input_length[b]);
       }
 
       utimer.Start();
       for (int i = 0; i < repeats; i++)
-        for (int b = 0; b < num_blocks; b++)
+        for (size_t b = 0; b < num_blocks; b++)
           Uncompress(compressed[b], comp, input_length[b], &output[b]);
       utimer.Stop();
 
@@ -458,8 +458,8 @@ static void Measure(const char* data,
   sort(utime, utime + kRuns);
   const int med = kRuns/2;
 
-  float comp_rate = (length / ctime[med]) * repeats / 1048576.0;
-  float uncomp_rate = (length / utime[med]) * repeats / 1048576.0;
+  float comp_rate = static_cast<float>((length / ctime[med]) * repeats / 1048576.0);
+  float uncomp_rate = static_cast<float>((length / utime[med]) * repeats / 1048576.0);
   string x = names[comp];
   x += ":";
   string urate = (uncomp_rate >= 0)
@@ -470,12 +470,12 @@ static void Measure(const char* data,
          x.c_str(),
          block_size/(1<<20),
          static_cast<int>(length), static_cast<uint32>(compressed_size),
-         (compressed_size * 100.0) / max<int>(1, length),
+         (compressed_size * 100.0) / max<size_t>(1, length),
          comp_rate,
          urate.c_str());
 }
 
-static int VerifyString(const string& input) {
+static size_t VerifyString(const string& input) {
   string compressed;
   DataEndingAtUnreadablePage i(input);
   const size_t written = snappy::Compress(i.data(), i.size(), &compressed);
@@ -521,13 +521,13 @@ static void VerifyIOVec(const string& input) {
   // Try uncompressing into an iovec containing a random number of entries
   // ranging from 1 to 10.
   char* buf = new char[input.size()];
-  ACMRandom rnd(input.size());
+  ACMRandom rnd(static_cast<uint32>(input.size()));
   size_t num = rnd.Next() % 10 + 1;
   if (input.size() < num) {
     num = input.size();
   }
   struct iovec* iov = new iovec[num];
-  int used_so_far = 0;
+  size_t used_so_far = 0;
   for (size_t i = 0; i < num; ++i) {
     iov[i].iov_base = buf + used_so_far;
     if (i == num - 1) {
@@ -537,7 +537,7 @@ static void VerifyIOVec(const string& input) {
       if (rnd.OneIn(5)) {
         iov[i].iov_len = 0;
       } else {
-        iov[i].iov_len = rnd.Uniform(input.size());
+        iov[i].iov_len = rnd.Uniform(static_cast<int32>(input.size()));
       }
     }
     used_so_far += iov[i].iov_len;
@@ -558,11 +558,11 @@ static void VerifyNonBlockedCompression(const string& input) {
   }
 
   string prefix;
-  Varint::Append32(&prefix, input.size());
+  Varint::Append32(&prefix, static_cast<uint32>(input.size()));
 
   // Setup compression table
   snappy::internal::WorkingMemory wmem;
-  int table_size;
+  size_t table_size;
   uint16* table = wmem.GetHashTable(input.size(), &table_size);
 
   // Compress entire input in one shot
@@ -591,7 +591,7 @@ static void VerifyNonBlockedCompression(const string& input) {
   {
     static const int kNumBlocks = 10;
     struct iovec vec[kNumBlocks];
-    const int block_size = 1 + input.size() / kNumBlocks;
+    const size_t block_size = 1 + input.size() / kNumBlocks;
     string iovec_data(block_size * kNumBlocks, 'x');
     for (int i = 0; i < kNumBlocks; i++) {
       vec[i].iov_base = string_as_array(&iovec_data) + i * block_size;
@@ -613,11 +613,11 @@ static string Expand(const string& input) {
   return data;
 }
 
-static int Verify(const string& input) {
+static size_t Verify(const string& input) {
   VLOG(1) << "Verifying input of size " << input.size();
 
   // Compress using string based routines
-  const int result = VerifyString(input);
+  const size_t result = VerifyString(input);
 
   // Verify using sink based routines
   VerifyStringSink(input);
@@ -716,10 +716,10 @@ TEST(CorruptedTest, VerifyCorrupted) {
 // invokes these routines.
 static void AppendLiteral(string* dst, const string& literal) {
   if (literal.empty()) return;
-  int n = literal.size() - 1;
+  size_t n = literal.size() - 1;
   if (n < 60) {
     // Fit length in tag byte
-    dst->push_back(0 | (n << 2));
+    dst->push_back(static_cast<char>(0 | (n << 2)));
   } else {
     // Encode in upcoming bytes
     char number[4];
@@ -734,10 +734,10 @@ static void AppendLiteral(string* dst, const string& literal) {
   *dst += literal;
 }
 
-static void AppendCopy(string* dst, int offset, int length) {
+static void AppendCopy(string* dst, size_t offset, size_t length) {
   while (length > 0) {
     // Figure out how much to copy in one shot
-    int to_copy;
+    size_t to_copy;
     if (length >= 68) {
       to_copy = 64;
     } else if (length > 64) {
@@ -749,14 +749,14 @@ static void AppendCopy(string* dst, int offset, int length) {
 
     if ((to_copy >= 4) && (to_copy < 12) && (offset < 2048)) {
       assert(to_copy-4 < 8);            // Must fit in 3 bits
-      dst->push_back(1 | ((to_copy-4) << 2) | ((offset >> 8) << 5));
-      dst->push_back(offset & 0xff);
+      dst->push_back(static_cast<char>(1 | ((to_copy-4) << 2) | ((offset >> 8) << 5)));
+      dst->push_back(static_cast<char>(offset & 0xff));
     } else if (offset < 65536) {
-      dst->push_back(2 | ((to_copy-1) << 2));
-      dst->push_back(offset & 0xff);
-      dst->push_back(offset >> 8);
+      dst->push_back(static_cast<char>(2 | ((to_copy-1) << 2)));
+      dst->push_back(static_cast<char>(offset & 0xff));
+      dst->push_back(static_cast<char>(offset >> 8));
     } else {
-      dst->push_back(3 | ((to_copy-1) << 2));
+      dst->push_back(static_cast<char>(3 | ((to_copy-1) << 2)));
       dst->push_back(offset & 0xff);
       dst->push_back((offset >> 8) & 0xff);
       dst->push_back((offset >> 16) & 0xff);
@@ -809,7 +809,7 @@ TEST(Snappy, RandomData) {
       len = 65536 + rnd.Uniform(65536);
     }
     while (x.size() < len) {
-      int run_len = 1;
+      size_t run_len = 1;
       if (rnd.OneIn(10)) {
         run_len = rnd.Skewed(8);
       }
@@ -833,16 +833,16 @@ TEST(Snappy, FourByteOffset) {
   string fragment2 = "some other string";
 
   // How many times each fragment is emitted.
-  const int n1 = 2;
-  const int n2 = 100000 / fragment2.size();
-  const int length = n1 * fragment1.size() + n2 * fragment2.size();
+  const size_t n1 = 2;
+  const size_t n2 = 100000 / fragment2.size();
+  const size_t length = n1 * fragment1.size() + n2 * fragment2.size();
 
   string compressed;
-  Varint::Append32(&compressed, length);
+  Varint::Append32(&compressed, static_cast<uint32>(length));
 
   AppendLiteral(&compressed, fragment1);
   string src = fragment1;
-  for (int i = 0; i < n2; i++) {
+  for (size_t i = 0; i < n2; i++) {
     AppendLiteral(&compressed, fragment2);
     src += fragment2;
   }
@@ -1302,20 +1302,20 @@ static void MeasureFile(const char* fname) {
   CHECK_OK(file::GetContents(fname, &fullinput, file::Defaults()));
   printf("%-40s :\n", fname);
 
-  int start_len = (FLAGS_start_len < 0) ? fullinput.size() : FLAGS_start_len;
-  int end_len = fullinput.size();
+  size_t start_len = (FLAGS_start_len < 0) ? fullinput.size() : FLAGS_start_len;
+  size_t end_len = fullinput.size();
   if (FLAGS_end_len >= 0) {
-    end_len = min<int>(fullinput.size(), FLAGS_end_len);
+    end_len = min<size_t>(fullinput.size(), FLAGS_end_len);
   }
-  for (int len = start_len; len <= end_len; len++) {
+  for (size_t len = start_len; len <= end_len; len++) {
     const char* const input = fullinput.data();
-    int repeats = (FLAGS_bytes + len) / (len + 1);
+    int repeats = static_cast<int>((FLAGS_bytes + len) / (len + 1));
     if (FLAGS_zlib)     Measure(input, len, ZLIB, repeats, 1024<<10);
     if (FLAGS_lzo)      Measure(input, len, LZO, repeats, 1024<<10);
     if (FLAGS_liblzf)   Measure(input, len, LIBLZF, repeats, 1024<<10);
     if (FLAGS_quicklz)  Measure(input, len, QUICKLZ, repeats, 1024<<10);
     if (FLAGS_fastlz)   Measure(input, len, FASTLZ, repeats, 1024<<10);
-    if (FLAGS_snappy)    Measure(input, len, SNAPPY, repeats, 4096<<10);
+    if (FLAGS_snappy)   Measure(input, len, SNAPPY, repeats, 4096<<10);
 
     // For block-size based measurements
     if (0 && FLAGS_snappy) {
@@ -1413,7 +1413,7 @@ static void BM_UIOVec(int iters, int arg) {
   const int kNumEntries = 10;
   struct iovec iov[kNumEntries];
   char *dst = new char[contents.size()];
-  int used_so_far = 0;
+  size_t used_so_far = 0;
   for (int i = 0; i < kNumEntries; ++i) {
     iov[i].iov_base = dst + used_so_far;
     if (used_so_far == contents.size()) {
